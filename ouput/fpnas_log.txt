FPNAS Optimizing ArchitectureBlock 0 ['Split', 'Id', 'Concat', 'Conv_8_1', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_8_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 1 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Conv_8_2']
Block 2 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Conv_8_2']
Final Model 
None
FPNAS Optimizing Architecture
Block 0 ['Split', 'Conv_8_1', 'Concat', 'Id', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Conv_8_1']
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_6_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 1 ['Add', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Id']
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_8_1', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Conv_4_1']
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_4_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 1 ['Split', 'Conv_8_1', 'Concat', 'Id', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 2 ['Split', 'Id', 'Add', 'Conv_6_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Conv_6_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Final Model 
Model: "functional_215"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
split_66 (Split)                [(None, 112, 224, 3) 0           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 56, 112, 24)  648         split_66[0][1]                   
__________________________________________________________________________________________________
inverted_residual_107 (Inverted (None, 56, 112, 24)  888         split_66[0][0]                   
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 56, 112, 24)  96          conv2d_101[0][0]                 
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 56, 112, 24)  648         split_66[0][1]                   
__________________________________________________________________________________________________
add_123 (Add)                   (None, 56, 112, 24)  0           inverted_residual_107[0][0]      
                                                                 batch_normalization_101[0][0]    
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 56, 112, 24)  96          conv2d_102[0][0]                 
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 112, 112, 24) 0           add_123[0][0]                    
                                                                 batch_normalization_102[0][0]    
__________________________________________________________________________________________________
flatten_107 (Flatten)           (None, 301056)       0           concatenate_66[0][0]             
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 1)            301057      flatten_107[0][0]                
==================================================================================================
Total params: 303,433
Trainable params: 303,217
Non-trainable params: 216
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Conv_8_2', 'Concat', 'Id', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Final Model 
Model: "functional_447"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
inverted_residual_228 (Inverted (None, 112, 112, 24) 1152        input_10[0][0]                   
__________________________________________________________________________________________________
split_144 (Split)               [(None, 56, 112, 24) 0           inverted_residual_228[0][0]      
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 112, 112, 24) 0           split_144[0][0]                  
                                                                 split_144[0][1]                  
__________________________________________________________________________________________________
flatten_223 (Flatten)           (None, 301056)       0           concatenate_144[0][0]            
__________________________________________________________________________________________________
dense_233 (Dense)               (None, 1)            301057      flatten_223[0][0]                
==================================================================================================
Total params: 302,209
Trainable params: 302,065
Non-trainable params: 144
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Conv_6_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 1 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Conv_6_2']
Block 2 ['Split', 'Conv_6_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 3 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Conv_6_1']
Block 4 ['Split', 'Id', 'Concat', 'Conv_8_1', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 5 ['Split', 'Id', 'Add', 'Conv_4_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Final Model 
Model: "functional_1733"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
split_2688 (Split)              [(None, 112, 224, 3) 0           input_11[0][0]                   
__________________________________________________________________________________________________
conv2d_3689 (Conv2D)            (None, 56, 112, 32)  864         split_2688[0][1]                 
__________________________________________________________________________________________________
inverted_residual_4081 (Inverte (None, 56, 112, 32)  1064        split_2688[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3689 (Batch (None, 56, 112, 32)  128         conv2d_3689[0][0]                
__________________________________________________________________________________________________
conv2d_3690 (Conv2D)            (None, 56, 112, 32)  864         split_2688[0][1]                 
__________________________________________________________________________________________________
add_4406 (Add)                  (None, 56, 112, 32)  0           inverted_residual_4081[0][0]     
                                                                 batch_normalization_3689[0][0]   
__________________________________________________________________________________________________
batch_normalization_3690 (Batch (None, 56, 112, 32)  128         conv2d_3690[0][0]                
__________________________________________________________________________________________________
concatenate_2688 (Concatenate)  (None, 112, 112, 32) 0           add_4406[0][0]                   
                                                                 batch_normalization_3690[0][0]   
__________________________________________________________________________________________________
split_2689 (Split)              [(None, 56, 112, 32) 0           concatenate_2688[0][0]           
__________________________________________________________________________________________________
add_4407 (Add)                  (None, 56, 112, 32)  0           split_2689[0][0]                 
                                                                 split_2689[0][1]                 
__________________________________________________________________________________________________
concatenate_2689 (Concatenate)  (None, 112, 112, 32) 0           add_4407[0][0]                   
                                                                 split_2689[0][1]                 
__________________________________________________________________________________________________
inverted_residual_4082 (Inverte (None, 56, 56, 32)   15680       concatenate_2689[0][0]           
__________________________________________________________________________________________________
inverted_residual_4083 (Inverte (None, 28, 28, 64)   21952       inverted_residual_4082[0][0]     
__________________________________________________________________________________________________
split_2690 (Split)              [(None, 14, 28, 64), 0           inverted_residual_4083[0][0]     
__________________________________________________________________________________________________
conv2d_3691 (Conv2D)            (None, 28, 28, 64)   18432       inverted_residual_4082[0][0]     
__________________________________________________________________________________________________
concatenate_2690 (Concatenate)  (None, 28, 28, 64)   0           split_2690[0][0]                 
                                                                 split_2690[0][1]                 
__________________________________________________________________________________________________
batch_normalization_3691 (Batch (None, 28, 28, 64)   256         conv2d_3691[0][0]                
__________________________________________________________________________________________________
add_4408 (Add)                  (None, 28, 28, 64)   0           concatenate_2690[0][0]           
                                                                 batch_normalization_3691[0][0]   
__________________________________________________________________________________________________
add_4409 (Add)                  (None, 28, 28, 64)   0           add_4408[0][0]                   
                                                                 add_4408[0][0]                   
__________________________________________________________________________________________________
add_4410 (Add)                  (None, 28, 28, 64)   0           add_4409[0][0]                   
                                                                 add_4408[0][0]                   
__________________________________________________________________________________________________
inverted_residual_4084 (Inverte (None, 28, 28, 64)   55936       add_4410[0][0]                   
__________________________________________________________________________________________________
split_2691 (Split)              [(None, 14, 28, 64), 0           inverted_residual_4084[0][0]     
__________________________________________________________________________________________________
conv2d_3692 (Conv2D)            (None, 14, 28, 128)  73728       split_2691[0][1]                 
__________________________________________________________________________________________________
inverted_residual_4085 (Inverte (None, 14, 28, 128)  107520      split_2691[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3692 (Batch (None, 14, 28, 128)  512         conv2d_3692[0][0]                
__________________________________________________________________________________________________
conv2d_3693 (Conv2D)            (None, 28, 28, 128)  73728       inverted_residual_4084[0][0]     
__________________________________________________________________________________________________
concatenate_2691 (Concatenate)  (None, 28, 28, 128)  0           inverted_residual_4085[0][0]     
                                                                 batch_normalization_3692[0][0]   
__________________________________________________________________________________________________
batch_normalization_3693 (Batch (None, 28, 28, 128)  512         conv2d_3693[0][0]                
__________________________________________________________________________________________________
add_4411 (Add)                  (None, 28, 28, 128)  0           concatenate_2691[0][0]           
                                                                 batch_normalization_3693[0][0]   
__________________________________________________________________________________________________
split_2692 (Split)              [(None, 14, 28, 128) 0           add_4411[0][0]                   
__________________________________________________________________________________________________
conv2d_3694 (Conv2D)            (None, 7, 14, 128)   147456      split_2692[0][1]                 
__________________________________________________________________________________________________
inverted_residual_4086 (Inverte (None, 7, 14, 128)   140288      split_2692[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3694 (Batch (None, 7, 14, 128)   512         conv2d_3694[0][0]                
__________________________________________________________________________________________________
conv2d_3695 (Conv2D)            (None, 7, 14, 128)   147456      split_2692[0][1]                 
__________________________________________________________________________________________________
add_4412 (Add)                  (None, 7, 14, 128)   0           inverted_residual_4086[0][0]     
                                                                 batch_normalization_3694[0][0]   
__________________________________________________________________________________________________
batch_normalization_3695 (Batch (None, 7, 14, 128)   512         conv2d_3695[0][0]                
__________________________________________________________________________________________________
concatenate_2692 (Concatenate)  (None, 14, 14, 128)  0           add_4412[0][0]                   
                                                                 batch_normalization_3695[0][0]   
__________________________________________________________________________________________________
flatten_866 (Flatten)           (None, 25088)        0           concatenate_2692[0][0]           
__________________________________________________________________________________________________
dense_877 (Dense)               (None, 1)            25089       flatten_866[0][0]                
==================================================================================================
Total params: 832,617
Trainable params: 823,201
Non-trainable params: 9,416
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_8_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 1 ['Split', 'Conv_8_2', 'Add', 'Id', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 2 ['Add', 'Id', 'Add', 'Conv_6_1', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Block 3 ['Split', 'Id', 'Concat', 'Conv_8_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 4 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'Id']
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_4_2', 'Id', 'No', 'Id']
Block 1 ['Split', 'Id', 'Concat', 'Conv_4_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 2 ['Split', 'Id', 'Concat', 'Conv_8_1', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 3 ['Split', 'Id', 'Add', 'Conv_4_1', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 4 ['Add', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Block 5 ['Split', 'Conv_4_2', 'Concat', 'Id', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 0 ['Split', 'Id', 'Concat', 'Conv_4_1', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 1 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_8_2', 'Id', 'No', 'Id']
Block 2 ['Split', 'Id', 'Add', 'Conv_8_1', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 3 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_4_2', 'No', 'Id', 'Id']
Block 4 ['Add', 'Id', 'Add', 'Conv_8_1', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Block 5 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Conv_4_2']
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_4_1', 'Id', 'No', 'Id']
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'Id']
Block 1 ['Split', 'Id', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Conv_4_2']
Block 2 ['Split', 'Id', 'Add', 'Conv_8_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 3 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Conv_4_1']
Block 4 ['Add', 'Id', 'Add', 'Conv_4_1', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Id']
Block 5 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_8_2', 'Id', 'No', 'Id']
Final Model 
Model: "functional_1285"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
add_4794 (Add)                  (None, 224, 224, 3)  0           input_2[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_3262 (Conv2D)            (None, 112, 112, 32) 864         input_2[0][0]                    
__________________________________________________________________________________________________
inverted_residual_3858 (Inverte (None, 112, 112, 32) 1376        add_4794[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3262 (Batch (None, 112, 112, 32) 128         conv2d_3262[0][0]                
__________________________________________________________________________________________________
add_4795 (Add)                  (None, 112, 112, 32) 0           inverted_residual_3858[0][0]     
                                                                 batch_normalization_3262[0][0]   
__________________________________________________________________________________________________
split_1903 (Split)              [(None, 56, 112, 32) 0           add_4795[0][0]                   
__________________________________________________________________________________________________
concatenate_1903 (Concatenate)  (None, 112, 112, 32) 0           split_1903[0][0]                 
                                                                 split_1903[0][1]                 
__________________________________________________________________________________________________
add_4796 (Add)                  (None, 112, 112, 32) 0           concatenate_1903[0][0]           
                                                                 add_4795[0][0]                   
__________________________________________________________________________________________________
inverted_residual_3859 (Inverte (None, 56, 56, 32)   10496       add_4796[0][0]                   
__________________________________________________________________________________________________
split_1904 (Split)              [(None, 28, 56, 32), 0           inverted_residual_3859[0][0]     
__________________________________________________________________________________________________
conv2d_3263 (Conv2D)            (None, 14, 28, 64)   18432       split_1904[0][1]                 
__________________________________________________________________________________________________
inverted_residual_3860 (Inverte (None, 14, 28, 64)   29184       split_1904[0][0]                 
__________________________________________________________________________________________________
batch_normalization_3263 (Batch (None, 14, 28, 64)   256         conv2d_3263[0][0]                
__________________________________________________________________________________________________
conv2d_3264 (Conv2D)            (None, 14, 28, 64)   18432       split_1904[0][1]                 
__________________________________________________________________________________________________
add_4797 (Add)                  (None, 14, 28, 64)   0           inverted_residual_3860[0][0]     
                                                                 batch_normalization_3263[0][0]   
__________________________________________________________________________________________________
batch_normalization_3264 (Batch (None, 14, 28, 64)   256         conv2d_3264[0][0]                
__________________________________________________________________________________________________
concatenate_1904 (Concatenate)  (None, 28, 28, 64)   0           add_4797[0][0]                   
                                                                 batch_normalization_3264[0][0]   
__________________________________________________________________________________________________
add_4798 (Add)                  (None, 28, 28, 64)   0           concatenate_1904[0][0]           
                                                                 concatenate_1904[0][0]           
__________________________________________________________________________________________________
add_4799 (Add)                  (None, 28, 28, 64)   0           add_4798[0][0]                   
                                                                 concatenate_1904[0][0]           
__________________________________________________________________________________________________
inverted_residual_3861 (Inverte (None, 28, 28, 64)   37376       add_4799[0][0]                   
__________________________________________________________________________________________________
conv2d_3265 (Conv2D)            (None, 28, 28, 128)  73728       inverted_residual_3861[0][0]     
__________________________________________________________________________________________________
inverted_residual_3862 (Inverte (None, 28, 28, 128)  54016       inverted_residual_3861[0][0]     
__________________________________________________________________________________________________
batch_normalization_3265 (Batch (None, 28, 28, 128)  512         conv2d_3265[0][0]                
__________________________________________________________________________________________________
conv2d_3266 (Conv2D)            (None, 28, 28, 128)  73728       inverted_residual_3861[0][0]     
__________________________________________________________________________________________________
add_4800 (Add)                  (None, 28, 28, 128)  0           inverted_residual_3862[0][0]     
                                                                 batch_normalization_3265[0][0]   
__________________________________________________________________________________________________
batch_normalization_3266 (Batch (None, 28, 28, 128)  512         conv2d_3266[0][0]                
__________________________________________________________________________________________________
add_4801 (Add)                  (None, 28, 28, 128)  0           add_4800[0][0]                   
                                                                 batch_normalization_3266[0][0]   
__________________________________________________________________________________________________
split_1905 (Split)              [(None, 14, 28, 128) 0           add_4801[0][0]                   
__________________________________________________________________________________________________
add_4802 (Add)                  (None, 14, 28, 128)  0           split_1905[0][0]                 
                                                                 split_1905[0][1]                 
__________________________________________________________________________________________________
conv2d_3267 (Conv2D)            (None, 7, 14, 128)   147456      split_1905[0][1]                 
__________________________________________________________________________________________________
inverted_residual_3863 (Inverte (None, 7, 14, 128)   280064      add_4802[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3267 (Batch (None, 7, 14, 128)   512         conv2d_3267[0][0]                
__________________________________________________________________________________________________
concatenate_1905 (Concatenate)  (None, 14, 14, 128)  0           inverted_residual_3863[0][0]     
                                                                 batch_normalization_3267[0][0]   
__________________________________________________________________________________________________
flatten_643 (Flatten)           (None, 25088)        0           concatenate_1905[0][0]           
__________________________________________________________________________________________________
dropout_642 (Dropout)           (None, 25088)        0           flatten_643[0][0]                
__________________________________________________________________________________________________
dense_644 (Dense)               (None, 1)            25089       dropout_642[0][0]                
==================================================================================================
Total params: 772,417
Trainable params: 762,657
Non-trainable params: 9,760
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'Id']
Block 1 ['Split', 'Conv_4_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 2 ['Add', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Final Model 
Model: "functional_643"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
add_1218 (Add)                  (None, 224, 224, 3)  0           input_1[0][0]                    
                                                                 input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_787 (Conv2D)             (None, 112, 112, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
inverted_residual_963 (Inverted (None, 112, 112, 32) 1064        add_1218[0][0]                   
__________________________________________________________________________________________________
batch_normalization_787 (BatchN (None, 112, 112, 32) 128         conv2d_787[0][0]                 
__________________________________________________________________________________________________
add_1219 (Add)                  (None, 112, 112, 32) 0           inverted_residual_963[0][0]      
                                                                 batch_normalization_787[0][0]    
__________________________________________________________________________________________________
inverted_residual_964 (Inverted (None, 56, 56, 64)   14720       add_1219[0][0]                   
__________________________________________________________________________________________________
split_627 (Split)               [(None, 28, 56, 64), 0           inverted_residual_964[0][0]      
__________________________________________________________________________________________________
conv2d_788 (Conv2D)             (None, 56, 56, 64)   18432       add_1219[0][0]                   
__________________________________________________________________________________________________
concatenate_627 (Concatenate)   (None, 56, 56, 64)   0           split_627[0][0]                  
                                                                 split_627[0][1]                  
__________________________________________________________________________________________________
batch_normalization_788 (BatchN (None, 56, 56, 64)   256         conv2d_788[0][0]                 
__________________________________________________________________________________________________
add_1220 (Add)                  (None, 56, 56, 64)   0           concatenate_627[0][0]            
                                                                 batch_normalization_788[0][0]    
__________________________________________________________________________________________________
conv2d_789 (Conv2D)             (None, 28, 28, 64)   36864       add_1220[0][0]                   
__________________________________________________________________________________________________
inverted_residual_965 (Inverted (None, 28, 28, 64)   55936       add_1220[0][0]                   
__________________________________________________________________________________________________
batch_normalization_789 (BatchN (None, 28, 28, 64)   256         conv2d_789[0][0]                 
__________________________________________________________________________________________________
add_1221 (Add)                  (None, 28, 28, 64)   0           inverted_residual_965[0][0]      
                                                                 batch_normalization_789[0][0]    
__________________________________________________________________________________________________
flatten_321 (Flatten)           (None, 50176)        0           add_1221[0][0]                   
__________________________________________________________________________________________________
dropout_321 (Dropout)           (None, 50176)        0           flatten_321[0][0]                
__________________________________________________________________________________________________
dense_322 (Dense)               (None, 1)            50177       dropout_321[0][0]                
==================================================================================================
Total params: 178,697
Trainable params: 175,937
Non-trainable params: 2,760
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Add', 'Id', 'No', 'Conv_4_2', 'Add', 'Id', 'No', 'Id', 'Id']
Block 1 ['Add', 'Id', 'Add', 'Id', 'No', 'Conv_4_2', 'None', 'Id', 'No', 'No', 'Id']
Block 2 ['Split', 'Id', 'Concat', 'Id', 'Id', 'No', 'Add', 'Conv_6_2', 'No', 'Id', 'Id']
Final Model 
Model: "functional_643"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_1003 (Conv2D)            (None, 112, 112, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1003 (Batch (None, 112, 112, 32) 128         conv2d_1003[0][0]                
__________________________________________________________________________________________________
inverted_residual_963 (Inverted (None, 112, 112, 32) 752         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1004 (Conv2D)            (None, 112, 112, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
add_1222 (Add)                  (None, 112, 112, 32) 0           batch_normalization_1003[0][0]   
                                                                 inverted_residual_963[0][0]      
__________________________________________________________________________________________________
batch_normalization_1004 (Batch (None, 112, 112, 32) 128         conv2d_1004[0][0]                
__________________________________________________________________________________________________
add_1223 (Add)                  (None, 112, 112, 32) 0           add_1222[0][0]                   
                                                                 batch_normalization_1004[0][0]   
__________________________________________________________________________________________________
conv2d_1005 (Conv2D)            (None, 56, 56, 64)   18432       add_1223[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1005 (Batch (None, 56, 56, 64)   256         conv2d_1005[0][0]                
__________________________________________________________________________________________________
inverted_residual_964 (Inverted (None, 56, 56, 64)   14720       add_1223[0][0]                   
__________________________________________________________________________________________________
add_1224 (Add)                  (None, 56, 56, 64)   0           batch_normalization_1005[0][0]   
                                                                 inverted_residual_964[0][0]      
__________________________________________________________________________________________________
split_518 (Split)               [(None, 28, 56, 64), 0           add_1224[0][0]                   
__________________________________________________________________________________________________
concatenate_518 (Concatenate)   (None, 56, 56, 64)   0           split_518[0][0]                  
                                                                 split_518[0][1]                  
__________________________________________________________________________________________________
conv2d_1006 (Conv2D)            (None, 28, 28, 64)   36864       add_1224[0][0]                   
__________________________________________________________________________________________________
inverted_residual_965 (Inverted (None, 28, 28, 64)   55936       concatenate_518[0][0]            
__________________________________________________________________________________________________
batch_normalization_1006 (Batch (None, 28, 28, 64)   256         conv2d_1006[0][0]                
__________________________________________________________________________________________________
add_1225 (Add)                  (None, 28, 28, 64)   0           inverted_residual_965[0][0]      
                                                                 batch_normalization_1006[0][0]   
__________________________________________________________________________________________________
flatten_321 (Flatten)           (None, 50176)        0           add_1225[0][0]                   
__________________________________________________________________________________________________
dropout_321 (Dropout)           (None, 50176)        0           flatten_321[0][0]                
__________________________________________________________________________________________________
dense_322 (Dense)               (None, 1)            50177       dropout_321[0][0]                
==================================================================================================
Total params: 179,377
Trainable params: 176,577
Non-trainable params: 2,800
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Conv_4_2']
Block 1 ['Split', 'Id', 'Add', 'Conv_6_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id']
Block 2 ['Split', 'Id', 'Concat', 'Conv_8_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_4_2', 'Id', 'No', 'Id']
Block 1 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_6_1', 'No', 'Id', 'Id']
Block 2 ['Split', 'Id', 'Concat', 'Conv_6_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
Block 0 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Conv_8_2', 'Id', 'No', 'Id']
Block 1 ['Split', 'Id', 'Concat', 'Conv_4_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 2 ['Add', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Block 0 ['Add', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id']
Block 1 ['Split', 'Conv_4_1', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id']
Block 2 ['Split', 'Id', 'Concat', 'Conv_4_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id']
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id'] Val Loss: 0.7441886067390442
Block 1 ['Split', 'Id', 'Concat', 'Conv_6_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id'] Val Loss: 1.9594610929489136
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Add', 'Conv_8_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id'] Val Loss: 1.064909815788269
Final Model 
Model: "functional_667"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
split_547 (Split)               [(None, 112, 224, 3) 0           input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_649 (Conv2D)             (None, 56, 112, 32)  864         split_547[0][1]                  
__________________________________________________________________________________________________
inverted_residual_785 (Inverted (None, 56, 112, 32)  1376        split_547[0][0]                  
__________________________________________________________________________________________________
batch_normalization_649 (BatchN (None, 56, 112, 32)  128         conv2d_649[0][0]                 
__________________________________________________________________________________________________
conv2d_650 (Conv2D)             (None, 56, 112, 32)  864         split_547[0][1]                  
__________________________________________________________________________________________________
add_812 (Add)                   (None, 56, 112, 32)  0           inverted_residual_785[0][0]      
                                                                 batch_normalization_649[0][0]    
__________________________________________________________________________________________________
batch_normalization_650 (BatchN (None, 56, 112, 32)  128         conv2d_650[0][0]                 
__________________________________________________________________________________________________
concatenate_547 (Concatenate)   (None, 112, 112, 32) 0           add_812[0][0]                    
                                                                 batch_normalization_650[0][0]    
__________________________________________________________________________________________________
flatten_333 (Flatten)           (None, 401408)       0           concatenate_547[0][0]            
__________________________________________________________________________________________________
dropout_333 (Dropout)           (None, 401408)       0           flatten_333[0][0]                
__________________________________________________________________________________________________
dense_335 (Dense)               (None, 1)            401409      dropout_333[0][0]                
==================================================================================================
Total params: 404,769
Trainable params: 404,481
Non-trainable params: 288
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Conv_8_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 0.4713754951953888
Block 1 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'Id'] Val Loss: 2.362506866455078
Final Model 
Model: "functional_1097"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
inverted_residual_1214 (Inverte (None, 112, 112, 32) 1376        input_3[0][0]                    
__________________________________________________________________________________________________
split_900 (Split)               [(None, 56, 112, 32) 0           inverted_residual_1214[0][0]     
__________________________________________________________________________________________________
conv2d_1174 (Conv2D)            (None, 112, 112, 32) 864         input_3[0][0]                    
__________________________________________________________________________________________________
concatenate_900 (Concatenate)   (None, 112, 112, 32) 0           split_900[0][0]                  
                                                                 split_900[0][1]                  
__________________________________________________________________________________________________
batch_normalization_1174 (Batch (None, 112, 112, 32) 128         conv2d_1174[0][0]                
__________________________________________________________________________________________________
add_1264 (Add)                  (None, 112, 112, 32) 0           concatenate_900[0][0]            
                                                                 batch_normalization_1174[0][0]   
__________________________________________________________________________________________________
add_1265 (Add)                  (None, 112, 112, 32) 0           add_1264[0][0]                   
                                                                 add_1264[0][0]                   
__________________________________________________________________________________________________
conv2d_1175 (Conv2D)            (None, 56, 56, 64)   18432       add_1264[0][0]                   
__________________________________________________________________________________________________
inverted_residual_1215 (Inverte (None, 56, 56, 64)   29184       add_1265[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1175 (Batch (None, 56, 56, 64)   256         conv2d_1175[0][0]                
__________________________________________________________________________________________________
add_1266 (Add)                  (None, 56, 56, 64)   0           inverted_residual_1215[0][0]     
                                                                 batch_normalization_1175[0][0]   
__________________________________________________________________________________________________
flatten_548 (Flatten)           (None, 200704)       0           add_1266[0][0]                   
__________________________________________________________________________________________________
dropout_548 (Dropout)           (None, 200704)       0           flatten_548[0][0]                
__________________________________________________________________________________________________
dense_551 (Dense)               (None, 1)            200705      dropout_548[0][0]                
==================================================================================================
Total params: 250,945
Trainable params: 249,441
Non-trainable params: 1,504
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Conv_4_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 0.6624687314033508
Block 1 ['Split', 'Id', 'Add', 'Id', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Conv_8_2'] Val Loss: 2.380988597869873
Block 0 ['Split', 'Id', 'Concat', 'Conv_4_2', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 6.430024147033691
Block 1 ['Add', 'Id', 'Add', 'Conv_6_2', 'No', 'Id', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 1.4586453437805176
Block 0 ['Split', 'Id', 'Add', 'Conv_4_2', 'Id', 'No', 'Concat', 'Id', 'Id', 'No', 'Id'] Val Loss: 0.24576452374458313
Block 1 ['Split', 'Conv_8_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 1.6760296821594238
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 4.30807638168335
Block 1 ['Conv_3_1'] Val Loss: 7.712119102478027
Block 2 ['Conv_3_1'] Val Loss: 6.895496368408203
Block 3 ['Conv_3_1'] Val Loss: 5.0054030418396
Block 4 ['Conv_3_1'] Val Loss: 2.322145700454712
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.2544128894805908
Block 1 ['Conv_3_1'] Val Loss: 7.50792932510376
Final Model 
Model: "functional_2439"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_2866 (Conv2D)         (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_2867 (Conv2D)         (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_1219 (Flatten)       (None, 3097600)           0         
_________________________________________________________________
dropout_1219 (Dropout)       (None, 3097600)           0         
_________________________________________________________________
dense_1226 (Dense)           (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 2.8052783012390137
Block 1 ['Conv_3_1'] Val Loss: 1.6885313987731934
Final Model 
Model: "functional_2453"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_2880 (Conv2D)         (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_2881 (Conv2D)         (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_1226 (Flatten)       (None, 3097600)           0         
_________________________________________________________________
dropout_1226 (Dropout)       (None, 3097600)           0         
_________________________________________________________________
dense_1234 (Dense)           (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.7194730043411255
Block 1 ['Conv_3_1'] Val Loss: 0.17392206192016602
Final Model 
Model: "functional_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_6 (Flatten)          (None, 3097600)           0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 3097600)           0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 4.8234710693359375
Block 1 ['Conv_3_1'] Val Loss: 1.573927402496338
Final Model 
Model: "functional_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_13 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 2.753474473953247
Block 1 ['Conv_3_1'] Val Loss: 11.473203659057617
Final Model 
Model: "functional_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_41 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_20 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 12.993576049804688
Block 1 ['Conv_3_1'] Val Loss: 3.3468308448791504
Final Model 
Model: "functional_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_27 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_31 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.703665018081665
Block 1 ['Conv_3_1'] Val Loss: 0.8392269611358643
Final Model 
Model: "functional_69"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_49 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_34 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_34 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_39 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 12.727941513061523
Block 1 ['Conv_3_1'] Val Loss: 0.6280964612960815
Final Model 
Model: "functional_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_53 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_41 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_41 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.2917373180389404
Block 1 ['Conv_3_1'] Val Loss: 0.5042436122894287
Final Model 
Model: "functional_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_57 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_48 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_48 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_55 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.5989989042282104
Block 1 ['Conv_3_1'] Val Loss: 0.17959536612033844
Final Model 
Model: "functional_111"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_61 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_55 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_55 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_63 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.6484516263008118
Block 1 ['Conv_3_1'] Val Loss: 0.9286746382713318
Final Model 
Model: "functional_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_65 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_66 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_62 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_62 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.016812991350889206
Block 1 ['Conv_3_1'] Val Loss: 1.0175185203552246
Final Model 
Model: "functional_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_11 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_69 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_69 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_69 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_79 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 5.266209602355957
Block 1 ['Conv_3_1'] Val Loss: 0.13609132170677185
Final Model 
Model: "functional_153"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_73 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_74 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_76 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_76 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_87 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.8791917562484741
Block 1 ['Conv_3_1'] Val Loss: 1.6185569763183594
Final Model 
Model: "functional_167"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_13 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_77 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_78 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_83 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_83 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_95 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.929421067237854
Block 1 ['Conv_3_1'] Val Loss: 1.750967264175415
Final Model 
Model: "functional_181"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_14 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_81 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_82 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_90 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_90 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_103 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.6248975396156311
Block 1 ['Conv_3_1'] Val Loss: 1.4684512615203857
Final Model 
Model: "functional_195"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_15 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_85 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_86 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_97 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_97 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_111 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'None', 'Id', 'No', 'No', 'Id'] Val Loss: 3.1401233673095703
Block 1 ['Split', 'Conv_4_2', 'Concat', 'Id', 'Id', 'No', 'Add', 'Id', 'No', 'Id', 'Id'] Val Loss: 4.399399757385254
Final Model 
Model: "functional_301"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_18 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_219 (Conv2D)             (None, 112, 112, 32) 864         input_18[0][0]                   
__________________________________________________________________________________________________
inverted_residual_104 (Inverted (None, 112, 112, 32) 1376        input_18[0][0]                   
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 112, 112, 32) 128         conv2d_219[0][0]                 
__________________________________________________________________________________________________
add_108 (Add)                   (None, 112, 112, 32) 0           inverted_residual_104[0][0]      
                                                                 batch_normalization_132[0][0]    
__________________________________________________________________________________________________
inverted_residual_105 (Inverted (None, 56, 56, 64)   14720       add_108[0][0]                    
__________________________________________________________________________________________________
split_85 (Split)                [(None, 28, 56, 64), 0           inverted_residual_105[0][0]      
__________________________________________________________________________________________________
conv2d_220 (Conv2D)             (None, 56, 56, 64)   18432       add_108[0][0]                    
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 56, 56, 64)   0           split_85[0][0]                   
                                                                 split_85[0][1]                   
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 56, 56, 64)   256         conv2d_220[0][0]                 
__________________________________________________________________________________________________
add_109 (Add)                   (None, 56, 56, 64)   0           concatenate_85[0][0]             
                                                                 batch_normalization_133[0][0]    
__________________________________________________________________________________________________
flatten_150 (Flatten)           (None, 200704)       0           add_109[0][0]                    
__________________________________________________________________________________________________
dropout_150 (Dropout)           (None, 200704)       0           flatten_150[0][0]                
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 1)            200705      dropout_150[0][0]                
==================================================================================================
Total params: 236,481
Trainable params: 235,489
Non-trainable params: 992
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Split', 'Id', 'Concat', 'Conv_6_2', 'Id', 'No', 'None', 'Id', 'No', 'No', 'Id'] Val Loss: 1.1175296306610107
Block 1 ['Add', 'Id', 'Add', 'Id', 'No', 'Id', 'Add', 'Conv_8_2', 'No', 'Id', 'Id'] Val Loss: 0.5256001353263855
Final Model 
Model: "functional_731"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
split_431 (Split)               [(None, 112, 224, 3) 0           input_19[0][0]                   
__________________________________________________________________________________________________
conv2d_746 (Conv2D)             (None, 56, 112, 32)  864         split_431[0][1]                  
__________________________________________________________________________________________________
inverted_residual_534 (Inverted (None, 56, 112, 32)  1064        split_431[0][0]                  
__________________________________________________________________________________________________
batch_normalization_659 (BatchN (None, 56, 112, 32)  128         conv2d_746[0][0]                 
__________________________________________________________________________________________________
concatenate_431 (Concatenate)   (None, 112, 112, 32) 0           inverted_residual_534[0][0]      
                                                                 batch_normalization_659[0][0]    
__________________________________________________________________________________________________
add_462 (Add)                   (None, 112, 112, 32) 0           concatenate_431[0][0]            
                                                                 concatenate_431[0][0]            
__________________________________________________________________________________________________
conv2d_747 (Conv2D)             (None, 56, 56, 64)   18432       concatenate_431[0][0]            
__________________________________________________________________________________________________
inverted_residual_535 (Inverted (None, 56, 56, 64)   29184       add_462[0][0]                    
__________________________________________________________________________________________________
batch_normalization_660 (BatchN (None, 56, 56, 64)   256         conv2d_747[0][0]                 
__________________________________________________________________________________________________
add_463 (Add)                   (None, 56, 56, 64)   0           inverted_residual_535[0][0]      
                                                                 batch_normalization_660[0][0]    
__________________________________________________________________________________________________
flatten_365 (Flatten)           (None, 200704)       0           add_463[0][0]                    
__________________________________________________________________________________________________
dropout_365 (Dropout)           (None, 200704)       0           flatten_365[0][0]                
__________________________________________________________________________________________________
dense_383 (Dense)               (None, 1)            200705      dropout_365[0][0]                
==================================================================================================
Total params: 250,633
Trainable params: 249,153
Non-trainable params: 1,480
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 2.0804202556610107
Block 1 ['Conv_3_1'] Val Loss: 2.341212272644043
Final Model 
Model: "functional_745"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_20 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_753 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_754 (Conv2D)          (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_373 (Flatten)        (None, 3097600)           0         
_________________________________________________________________
dropout_374 (Dropout)        (None, 3097600)           0         
_________________________________________________________________
dense_392 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.1606907844543457
Block 1 ['Conv_3_1'] Val Loss: 2.4564480781555176
Final Model 
Model: "functional_759"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_21 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_757 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_758 (Conv2D)          (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_380 (Flatten)        (None, 3097600)           0         
_________________________________________________________________
dropout_381 (Dropout)        (None, 3097600)           0         
_________________________________________________________________
dense_400 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.4753855466842651
Block 1 ['Conv_3_1'] Val Loss: 0.6814043521881104
Final Model 
Model: "functional_773"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_761 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_762 (Conv2D)          (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_387 (Flatten)        (None, 3097600)           0         
_________________________________________________________________
dropout_388 (Dropout)        (None, 3097600)           0         
_________________________________________________________________
dense_408 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.5267785787582397
Final Model 
Model: "functional_781"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_23 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_764 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_391 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_392 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_413 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.8353346586227417
Final Model 
Model: "functional_789"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_24 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_766 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_395 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_396 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_418 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 2.3898465633392334
Final Model 
Model: "functional_797"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_25 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_768 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_399 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_400 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_423 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 5.363889694213867
Final Model 
Model: "functional_805"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_26 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_770 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_403 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_404 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_428 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 4.987587928771973
Block 1 ['Conv_3_1'] Val Loss: 4.778165817260742
Final Model 
Model: "functional_819"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_27 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_773 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_774 (Conv2D)          (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_410 (Flatten)        (None, 3097600)           0         
_________________________________________________________________
dropout_411 (Dropout)        (None, 3097600)           0         
_________________________________________________________________
dense_436 (Dense)            (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.6583446264266968
Final Model 
Model: "functional_827"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_28 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_776 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_414 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_415 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_441 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 15.084102630615234
Final Model 
Model: "functional_835"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_29 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_778 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_418 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_419 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_446 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 2.108954906463623
Final Model 
Model: "functional_843"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_30 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_780 (Conv2D)          (None, 222, 222, 32)      896       
_________________________________________________________________
flatten_422 (Flatten)        (None, 1577088)           0         
_________________________________________________________________
dropout_423 (Dropout)        (None, 1577088)           0         
_________________________________________________________________
dense_451 (Dense)            (None, 1)                 1577089   
=================================================================
Total params: 1,577,985
Trainable params: 1,577,985
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_2'] Val Loss: 0.35975122451782227
Final Model 
Model: "functional_851"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_31 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_782 (Conv2D)          (None, 111, 111, 32)      896       
_________________________________________________________________
flatten_426 (Flatten)        (None, 394272)            0         
_________________________________________________________________
dropout_427 (Dropout)        (None, 394272)            0         
_________________________________________________________________
dense_456 (Dense)            (None, 1)                 394273    
=================================================================
Total params: 395,169
Trainable params: 395,169
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_2'] Val Loss: 0.41195109486579895
Final Model 
Model: "functional_859"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_32 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_784 (Conv2D)          (None, 111, 111, 32)      896       
_________________________________________________________________
flatten_430 (Flatten)        (None, 394272)            0         
_________________________________________________________________
dropout_431 (Dropout)        (None, 394272)            0         
_________________________________________________________________
dense_461 (Dense)            (None, 1)                 394273    
=================================================================
Total params: 395,169
Trainable params: 395,169
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_2'] Val Loss: 6.095259666442871
Final Model 
Model: "functional_867"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_786 (Conv2D)          (None, 111, 111, 32)      896       
_________________________________________________________________
flatten_434 (Flatten)        (None, 394272)            0         
_________________________________________________________________
dropout_435 (Dropout)        (None, 394272)            0         
_________________________________________________________________
dense_466 (Dense)            (None, 1)                 394273    
=================================================================
Total params: 395,169
Trainable params: 395,169
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_2'] Val Loss: 3.714435577392578
Final Model 
Model: "functional_875"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_34 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_788 (Conv2D)          (None, 111, 111, 32)      896       
_________________________________________________________________
flatten_438 (Flatten)        (None, 394272)            0         
_________________________________________________________________
dropout_439 (Dropout)        (None, 394272)            0         
_________________________________________________________________
dense_471 (Dense)            (None, 1)                 394273    
=================================================================
Total params: 395,169
Trainable params: 395,169
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Conv_3_2'] Val Loss: 1.1797999143600464
Block 1 ['Conv_3_2'] Val Loss: 0.6144968271255493
Final Model 
Model: "functional_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 111, 111, 32)      896       
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 55, 55, 64)        18496     
_________________________________________________________________
flatten_6 (Flatten)          (None, 193600)            0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 193600)            0         
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 193601    
=================================================================
Total params: 212,993
Trainable params: 212,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 83.35813903808594
Block 1 ['Conv_3_1'] Val Loss: 4.159182548522949
Block 2 ['Conv_3_1'] Val Loss: 37.890159606933594
Final Model 
Model: "functional_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 220, 220, 64)      18496     
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 218, 218, 64)      36928     
_________________________________________________________________
flatten_16 (Flatten)         (None, 3041536)           0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 3041536)           0         
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 3041537   
=================================================================
Total params: 3,097,857
Trainable params: 3,097,857
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 23.649494171142578
Final Model 
Model: "functional_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 222, 222, 64)      1792      
_________________________________________________________________
flatten_20 (Flatten)         (None, 3154176)           0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 3154176)           0         
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 3154177   
=================================================================
Total params: 3,155,969
Trainable params: 3,155,969
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 0.7230970859527588
Final Model 
Model: "functional_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 222, 222, 64)      1792      
_________________________________________________________________
flatten_25 (Flatten)         (None, 3154176)           0         
_________________________________________________________________
dropout_26 (Dropout)         (None, 3154176)           0         
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 3154177   
=================================================================
Total params: 3,155,969
Trainable params: 3,155,969
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 1.1544209718704224
Block 1 ['Conv_3_1'] Val Loss: 9.86380386352539
Final Model 
Model: "functional_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_32 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_33 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_37 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 11.436928749084473
Block 1 ['Conv_3_1'] Val Loss: 11.436928749084473
Final Model 
Model: "functional_77"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_26 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_40 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_41 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_39 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 11.436928749084473
Block 1 ['Conv_3_1'] Val Loss: 11.436928749084473
Final Model 
Model: "functional_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_47 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_48 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_40 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 11.436928749084473
Block 1 ['Conv_3_1'] Val Loss: 11.436928749084473
Final Model 
Model: "functional_105"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_54 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_55 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_41 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 11.436928749084473
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 20.472145080566406
FPNAS Optimizing Architecture
Block 0 ['Conv_3_1'] Val Loss: 5.900636196136475
Block 1 ['Conv_3_1'] Val Loss: 2.110836982727051
Final Model 
Model: "functional_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_12 (InputLayer)        [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 222, 222, 32)      896       
_________________________________________________________________
conv2d_46 (Conv2D)           (None, 220, 220, 64)      18496     
_________________________________________________________________
flatten_71 (Flatten)         (None, 3097600)           0         
_________________________________________________________________
dropout_72 (Dropout)         (None, 3097600)           0         
_________________________________________________________________
dense_49 (Dense)             (None, 1)                 3097601   
=================================================================
Total params: 3,116,993
Trainable params: 3,116,993
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['None', 'Conv_3_1', 'No'] Val Loss: 2.929035186767578
Block 1 ['None', 'Conv_3_1', 'No'] Val Loss: 11.83504581451416
Final Model 
Model: "functional_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 224, 224, 32)      896       
_________________________________________________________________
conv2d_61 (Conv2D)           (None, 224, 224, 64)      18496     
_________________________________________________________________
flatten_29 (Flatten)         (None, 3211264)           0         
_________________________________________________________________
dropout_29 (Dropout)         (None, 3211264)           0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 3211265   
=================================================================
Total params: 3,230,657
Trainable params: 3,230,657
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['None', 'Conv_5_1', 'No'] Val Loss: 19.37448501586914
Block 1 ['None', 'Conv_3_1', 'No'] Val Loss: 108.5950927734375
Block 2 ['None', 'Conv_3_1', 'No'] Val Loss: 5.757429122924805
Final Model 
Model: "functional_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_97 (Conv2D)           (None, 224, 224, 32)      2432      
_________________________________________________________________
conv2d_108 (Conv2D)          (None, 224, 224, 64)      18496     
_________________________________________________________________
conv2d_130 (Conv2D)          (None, 224, 224, 64)      36928     
_________________________________________________________________
flatten_66 (Flatten)         (None, 3211264)           0         
_________________________________________________________________
dropout_66 (Dropout)         (None, 3211264)           0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 3211265   
=================================================================
Total params: 3,269,121
Trainable params: 3,269,121
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['None', 'Conv_3_1', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 92.5985107421875
FPNAS Optimizing Architecture
Block 0 ['None', 'Conv_5_1', 'No', 'None', 'Id', 'No'] Val Loss: 1.507572054862976
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 2.2552192211151123
Block 2 ['None', 'Id', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.5230697989463806
Final Model 
Model: "functional_313"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
conv2d_229 (Conv2D)          (None, 224, 224, 32)      2432      
_________________________________________________________________
max_pooling2d_49 (MaxPooling (None, 112, 112, 32)      0         
_________________________________________________________________
conv2d_339 (Conv2D)          (None, 112, 112, 64)      18496     
_________________________________________________________________
max_pooling2d_73 (MaxPooling (None, 56, 56, 64)        0         
_________________________________________________________________
conv2d_545 (Conv2D)          (None, 56, 56, 64)        36928     
_________________________________________________________________
max_pooling2d_117 (MaxPoolin (None, 28, 28, 64)        0         
_________________________________________________________________
flatten_156 (Flatten)        (None, 50176)             0         
_________________________________________________________________
dropout_156 (Dropout)        (None, 50176)             0         
_________________________________________________________________
dense (Dense)                (None, 1)                 50177     
=================================================================
Total params: 108,033
Trainable params: 108,033
Non-trainable params: 0
_________________________________________________________________
FPNAS Optimizing Architecture
FPNAS Optimizing Architecture
Block 0 ['Add', 'Conv_3_1', 'Id', 'Add', 'Conv_3_1', 'Id'] Val Loss: 1.3615782260894775
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.4809894859790802
Block 2 ['None', 'Id', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.36228930950164795
Final Model 
Model: "functional_675"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_740 (Conv2D)             (None, 224, 224, 32) 896         input_3[0][0]                    
__________________________________________________________________________________________________
conv2d_741 (Conv2D)             (None, 224, 224, 32) 1024        conv2d_740[120][0]               
__________________________________________________________________________________________________
conv2d_742 (Conv2D)             (None, 224, 224, 32) 96          input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_406 (BatchN (None, 224, 224, 32) 128         conv2d_741[120][0]               
__________________________________________________________________________________________________
batch_normalization_407 (BatchN (None, 224, 224, 32) 128         conv2d_742[120][0]               
__________________________________________________________________________________________________
add_203 (Add)                   (None, 224, 224, 32) 0           batch_normalization_406[120][0]  
                                                                 batch_normalization_407[120][0]  
__________________________________________________________________________________________________
conv2d_743 (Conv2D)             (None, 224, 224, 32) 9248        add_203[120][0]                  
__________________________________________________________________________________________________
conv2d_744 (Conv2D)             (None, 224, 224, 32) 1024        conv2d_743[120][0]               
__________________________________________________________________________________________________
conv2d_745 (Conv2D)             (None, 224, 224, 32) 96          input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_408 (BatchN (None, 224, 224, 32) 128         conv2d_744[120][0]               
__________________________________________________________________________________________________
batch_normalization_409 (BatchN (None, 224, 224, 32) 128         conv2d_745[120][0]               
__________________________________________________________________________________________________
add_204 (Add)                   (None, 224, 224, 32) 0           batch_normalization_408[120][0]  
                                                                 batch_normalization_409[120][0]  
__________________________________________________________________________________________________
max_pooling2d_161 (MaxPooling2D (None, 112, 112, 32) 0           add_204[120][0]                  
__________________________________________________________________________________________________
conv2d_1035 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_161[120][0]        
__________________________________________________________________________________________________
max_pooling2d_225 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_1035[61][0]               
__________________________________________________________________________________________________
conv2d_1241 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_225[61][0]         
__________________________________________________________________________________________________
max_pooling2d_269 (MaxPooling2D (None, 28, 28, 64)   0           conv2d_1241[2][0]                
__________________________________________________________________________________________________
flatten_337 (Flatten)           (None, 50176)        0           max_pooling2d_269[2][0]          
__________________________________________________________________________________________________
dropout_337 (Dropout)           (None, 50176)        0           flatten_337[0][0]                
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            50177       dropout_337[0][0]                
==================================================================================================
Total params: 118,497
Trainable params: 118,241
Non-trainable params: 256
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Conv_5_1', 'Id', 'None', 'Id', 'No'] Val Loss: 4.065179347991943
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.2574252188205719
Block 0 ['None', 'Conv_5_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.31102436780929565
Block 1 ['None', 'Conv_5_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.49786823987960815
Block 0 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.39966723322868347
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.40323084592819214
Block 0 ['None', 'Conv_3_1', 'No', 'Add', 'Id', 'Conv_3_1'] Val Loss: 0.286337286233902
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 1.299588918685913
Final Model 
Model: "functional_1621"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_2793 (Conv2D)            (None, 224, 224, 32) 896         input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_2794 (Conv2D)            (None, 224, 224, 32) 896         input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_2795 (Conv2D)            (None, 224, 224, 32) 1024        conv2d_2793[61][0]               
__________________________________________________________________________________________________
conv2d_2796 (Conv2D)            (None, 224, 224, 32) 1024        conv2d_2794[61][0]               
__________________________________________________________________________________________________
batch_normalization_1526 (Batch (None, 224, 224, 32) 128         conv2d_2795[61][0]               
__________________________________________________________________________________________________
batch_normalization_1527 (Batch (None, 224, 224, 32) 128         conv2d_2796[61][0]               
__________________________________________________________________________________________________
add_763 (Add)                   (None, 224, 224, 32) 0           batch_normalization_1526[61][0]  
                                                                 batch_normalization_1527[61][0]  
__________________________________________________________________________________________________
max_pooling2d_608 (MaxPooling2D (None, 112, 112, 32) 0           add_763[61][0]                   
__________________________________________________________________________________________________
conv2d_3026 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_608[61][0]         
__________________________________________________________________________________________________
max_pooling2d_659 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_3026[2][0]                
__________________________________________________________________________________________________
flatten_810 (Flatten)           (None, 200704)       0           max_pooling2d_659[2][0]          
__________________________________________________________________________________________________
dropout_810 (Dropout)           (None, 200704)       0           flatten_810[0][0]                
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            200705      dropout_810[0][0]                
==================================================================================================
Total params: 223,297
Trainable params: 223,169
Non-trainable params: 128
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Conv_5_1', 'None', 'Conv_5_1', 'No'] Val Loss: 0.7288614511489868
Block 1 ['None', 'Id', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.4025469720363617
Block 2 ['Add', 'Conv_3_1', 'Conv_3_1', 'Add', 'Conv_3_1', 'Id'] Val Loss: 0.8109025955200195
Block 3 ['None', 'Conv_3_1', 'No', 'Add', 'Conv_3_1', 'Id'] Val Loss: 3.394746780395508
Block 4 ['Add', 'Conv_3_1', 'Conv_3_1', 'None', 'Id', 'No'] Val Loss: 0.7505298256874084
Final Model 
Model: "functional_2213"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_3292 (Conv2D)            (None, 224, 224, 32) 2432        input_5[0][0]                    
__________________________________________________________________________________________________
conv2d_3293 (Conv2D)            (None, 224, 224, 32) 96          input_5[0][0]                    
__________________________________________________________________________________________________
conv2d_3294 (Conv2D)            (None, 224, 224, 32) 1024        conv2d_3292[238][0]              
__________________________________________________________________________________________________
batch_normalization_1798 (Batch (None, 224, 224, 32) 128         conv2d_3293[238][0]              
__________________________________________________________________________________________________
batch_normalization_1799 (Batch (None, 224, 224, 32) 128         conv2d_3294[238][0]              
__________________________________________________________________________________________________
add_899 (Add)                   (None, 224, 224, 32) 0           batch_normalization_1798[238][0] 
                                                                 batch_normalization_1799[238][0] 
__________________________________________________________________________________________________
conv2d_3295 (Conv2D)            (None, 224, 224, 32) 25632       add_899[238][0]                  
__________________________________________________________________________________________________
max_pooling2d_718 (MaxPooling2D (None, 112, 112, 32) 0           conv2d_3295[238][0]              
__________________________________________________________________________________________________
conv2d_3583 (Conv2D)            (None, 112, 112, 64) 51264       max_pooling2d_718[238][0]        
__________________________________________________________________________________________________
max_pooling2d_780 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_3583[179][0]              
__________________________________________________________________________________________________
conv2d_3659 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_780[179][0]        
__________________________________________________________________________________________________
conv2d_3660 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_780[179][0]        
__________________________________________________________________________________________________
conv2d_3661 (Conv2D)            (None, 56, 56, 64)   4096        conv2d_3659[120][0]              
__________________________________________________________________________________________________
conv2d_3662 (Conv2D)            (None, 56, 56, 64)   4096        conv2d_3660[120][0]              
__________________________________________________________________________________________________
batch_normalization_2000 (Batch (None, 56, 56, 64)   256         conv2d_3661[120][0]              
__________________________________________________________________________________________________
batch_normalization_2001 (Batch (None, 56, 56, 64)   256         conv2d_3662[120][0]              
__________________________________________________________________________________________________
add_1000 (Add)                  (None, 56, 56, 64)   0           batch_normalization_2000[120][0] 
                                                                 batch_normalization_2001[120][0] 
__________________________________________________________________________________________________
conv2d_3663 (Conv2D)            (None, 56, 56, 64)   36928       add_1000[120][0]                 
__________________________________________________________________________________________________
conv2d_3664 (Conv2D)            (None, 56, 56, 64)   4096        conv2d_3663[120][0]              
__________________________________________________________________________________________________
conv2d_3665 (Conv2D)            (None, 56, 56, 64)   4096        max_pooling2d_780[179][0]        
__________________________________________________________________________________________________
batch_normalization_2002 (Batch (None, 56, 56, 64)   256         conv2d_3664[120][0]              
__________________________________________________________________________________________________
batch_normalization_2003 (Batch (None, 56, 56, 64)   256         conv2d_3665[120][0]              
__________________________________________________________________________________________________
add_1001 (Add)                  (None, 56, 56, 64)   0           batch_normalization_2002[120][0] 
                                                                 batch_normalization_2003[120][0] 
__________________________________________________________________________________________________
max_pooling2d_797 (MaxPooling2D (None, 28, 28, 64)   0           add_1001[120][0]                 
__________________________________________________________________________________________________
conv2d_3918 (Conv2D)            (None, 28, 28, 128)  73856       max_pooling2d_797[120][0]        
__________________________________________________________________________________________________
conv2d_3919 (Conv2D)            (None, 28, 28, 128)  147584      conv2d_3918[61][0]               
__________________________________________________________________________________________________
conv2d_3920 (Conv2D)            (None, 28, 28, 128)  16384       conv2d_3919[61][0]               
__________________________________________________________________________________________________
conv2d_3921 (Conv2D)            (None, 28, 28, 128)  8192        max_pooling2d_797[120][0]        
__________________________________________________________________________________________________
batch_normalization_2140 (Batch (None, 28, 28, 128)  512         conv2d_3920[61][0]               
__________________________________________________________________________________________________
batch_normalization_2141 (Batch (None, 28, 28, 128)  512         conv2d_3921[61][0]               
__________________________________________________________________________________________________
add_1070 (Add)                  (None, 28, 28, 128)  0           batch_normalization_2140[61][0]  
                                                                 batch_normalization_2141[61][0]  
__________________________________________________________________________________________________
max_pooling2d_854 (MaxPooling2D (None, 14, 14, 128)  0           add_1070[61][0]                  
__________________________________________________________________________________________________
conv2d_4114 (Conv2D)            (None, 14, 14, 128)  147584      max_pooling2d_854[61][0]         
__________________________________________________________________________________________________
conv2d_4115 (Conv2D)            (None, 14, 14, 128)  147584      max_pooling2d_854[61][0]         
__________________________________________________________________________________________________
conv2d_4116 (Conv2D)            (None, 14, 14, 128)  16384       conv2d_4114[2][0]                
__________________________________________________________________________________________________
conv2d_4117 (Conv2D)            (None, 14, 14, 128)  16384       conv2d_4115[2][0]                
__________________________________________________________________________________________________
batch_normalization_2248 (Batch (None, 14, 14, 128)  512         conv2d_4116[2][0]                
__________________________________________________________________________________________________
batch_normalization_2249 (Batch (None, 14, 14, 128)  512         conv2d_4117[2][0]                
__________________________________________________________________________________________________
add_1124 (Add)                  (None, 14, 14, 128)  0           batch_normalization_2248[2][0]   
                                                                 batch_normalization_2249[2][0]   
__________________________________________________________________________________________________
max_pooling2d_895 (MaxPooling2D (None, 7, 7, 128)    0           add_1124[2][0]                   
__________________________________________________________________________________________________
flatten_1106 (Flatten)          (None, 6272)         0           max_pooling2d_895[2][0]          
__________________________________________________________________________________________________
dropout_1106 (Dropout)          (None, 6272)         0           flatten_1106[0][0]               
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1)            6273        dropout_1106[0][0]               
==================================================================================================
Total params: 791,169
Trainable params: 789,505
Non-trainable params: 1,664
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['None', 'Conv_5_1', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.3434624671936035
Block 1 ['None', 'Id', 'No', 'Add', 'Id', 'Conv_5_1'] Val Loss: 0.2590869665145874
Block 2 ['Add', 'Id', 'Conv_3_1', 'Add', 'Conv_3_1', 'Id'] Val Loss: 0.28501394391059875
Final Model 
Model: "functional_2569"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_4490 (Conv2D)            (None, 224, 224, 8)  608         input_6[0][0]                    
__________________________________________________________________________________________________
conv2d_4491 (Conv2D)            (None, 224, 224, 8)  1608        conv2d_4490[120][0]              
__________________________________________________________________________________________________
max_pooling2d_980 (MaxPooling2D (None, 112, 112, 8)  0           conv2d_4491[120][0]              
__________________________________________________________________________________________________
conv2d_4685 (Conv2D)            (None, 112, 112, 8)  1608        max_pooling2d_980[120][0]        
__________________________________________________________________________________________________
conv2d_4686 (Conv2D)            (None, 112, 112, 8)  64          max_pooling2d_980[120][0]        
__________________________________________________________________________________________________
conv2d_4687 (Conv2D)            (None, 112, 112, 8)  64          conv2d_4685[61][0]               
__________________________________________________________________________________________________
batch_normalization_2558 (Batch (None, 112, 112, 8)  32          conv2d_4686[61][0]               
__________________________________________________________________________________________________
batch_normalization_2559 (Batch (None, 112, 112, 8)  32          conv2d_4687[61][0]               
__________________________________________________________________________________________________
add_1279 (Add)                  (None, 112, 112, 8)  0           batch_normalization_2558[61][0]  
                                                                 batch_normalization_2559[61][0]  
__________________________________________________________________________________________________
max_pooling2d_1020 (MaxPooling2 (None, 56, 56, 8)    0           add_1279[61][0]                  
__________________________________________________________________________________________________
conv2d_4718 (Conv2D)            (None, 56, 56, 16)   1168        max_pooling2d_1020[61][0]        
__________________________________________________________________________________________________
conv2d_4719 (Conv2D)            (None, 56, 56, 16)   128         max_pooling2d_1020[61][0]        
__________________________________________________________________________________________________
conv2d_4720 (Conv2D)            (None, 56, 56, 16)   256         conv2d_4718[2][0]                
__________________________________________________________________________________________________
batch_normalization_2574 (Batch (None, 56, 56, 16)   64          conv2d_4719[2][0]                
__________________________________________________________________________________________________
batch_normalization_2575 (Batch (None, 56, 56, 16)   64          conv2d_4720[2][0]                
__________________________________________________________________________________________________
add_1287 (Add)                  (None, 56, 56, 16)   0           batch_normalization_2574[2][0]   
                                                                 batch_normalization_2575[2][0]   
__________________________________________________________________________________________________
conv2d_4721 (Conv2D)            (None, 56, 56, 16)   2320        add_1287[2][0]                   
__________________________________________________________________________________________________
conv2d_4722 (Conv2D)            (None, 56, 56, 16)   256         conv2d_4721[2][0]                
__________________________________________________________________________________________________
conv2d_4723 (Conv2D)            (None, 56, 56, 16)   128         max_pooling2d_1020[61][0]        
__________________________________________________________________________________________________
batch_normalization_2576 (Batch (None, 56, 56, 16)   64          conv2d_4722[2][0]                
__________________________________________________________________________________________________
batch_normalization_2577 (Batch (None, 56, 56, 16)   64          conv2d_4723[2][0]                
__________________________________________________________________________________________________
add_1288 (Add)                  (None, 56, 56, 16)   0           batch_normalization_2576[2][0]   
                                                                 batch_normalization_2577[2][0]   
__________________________________________________________________________________________________
max_pooling2d_1030 (MaxPooling2 (None, 28, 28, 16)   0           add_1288[2][0]                   
__________________________________________________________________________________________________
flatten_1284 (Flatten)          (None, 12544)        0           max_pooling2d_1030[2][0]         
__________________________________________________________________________________________________
dropout_1284 (Dropout)          (None, 12544)        0           flatten_1284[0][0]               
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            12545       dropout_1284[0][0]               
==================================================================================================
Total params: 21,073
Trainable params: 20,913
Non-trainable params: 160
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Conv_3_1', 'Id', 'None', 'Conv_3_1', 'No'] Val Loss: 0.3863067626953125
Block 1 ['None', 'Id', 'No', 'Add', 'Conv_3_1', 'Conv_3_1'] Val Loss: 0.27962735295295715
Block 2 ['None', 'Conv_3_1', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.2140938639640808
Final Model 
Model: "functional_355"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 224, 224, 8)  224         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 224, 224, 8)  64          conv2d_60[120][0]                
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 224, 224, 8)  24          input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 224, 224, 8)  32          conv2d_61[120][0]                
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 224, 224, 8)  32          conv2d_62[120][0]                
__________________________________________________________________________________________________
add_18 (Add)                    (None, 224, 224, 8)  0           batch_normalization_36[120][0]   
                                                                 batch_normalization_37[120][0]   
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 224, 224, 8)  584         add_18[120][0]                   
__________________________________________________________________________________________________
max_pooling2d_12 (MaxPooling2D) (None, 112, 112, 8)  0           conv2d_63[120][0]                
__________________________________________________________________________________________________
conv2d_321 (Conv2D)             (None, 112, 112, 8)  584         max_pooling2d_12[120][0]         
__________________________________________________________________________________________________
conv2d_322 (Conv2D)             (None, 112, 112, 8)  584         max_pooling2d_12[120][0]         
__________________________________________________________________________________________________
conv2d_323 (Conv2D)             (None, 112, 112, 8)  64          conv2d_321[61][0]                
__________________________________________________________________________________________________
conv2d_324 (Conv2D)             (None, 112, 112, 8)  64          conv2d_322[61][0]                
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 112, 112, 8)  32          conv2d_323[61][0]                
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 112, 112, 8)  32          conv2d_324[61][0]                
__________________________________________________________________________________________________
add_89 (Add)                    (None, 112, 112, 8)  0           batch_normalization_178[61][0]   
                                                                 batch_normalization_179[61][0]   
__________________________________________________________________________________________________
max_pooling2d_68 (MaxPooling2D) (None, 56, 56, 8)    0           add_89[61][0]                    
__________________________________________________________________________________________________
conv2d_560 (Conv2D)             (None, 56, 56, 16)   1168        max_pooling2d_68[61][0]          
__________________________________________________________________________________________________
conv2d_561 (Conv2D)             (None, 56, 56, 16)   2320        conv2d_560[2][0]                 
__________________________________________________________________________________________________
max_pooling2d_122 (MaxPooling2D (None, 28, 28, 16)   0           conv2d_561[2][0]                 
__________________________________________________________________________________________________
flatten_177 (Flatten)           (None, 12544)        0           max_pooling2d_122[2][0]          
__________________________________________________________________________________________________
dropout_177 (Dropout)           (None, 12544)        0           flatten_177[0][0]                
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            12545       dropout_177[0][0]                
==================================================================================================
Total params: 18,353
Trainable params: 18,289
Non-trainable params: 64
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Conv_5_1', 'Id', 'None', 'Conv_5_1', 'No'] Val Loss: 1.438042402267456
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.18334166705608368
Block 2 ['None', 'Conv_3_1', 'No', 'Add', 'Id', 'Conv_3_1'] Val Loss: 0.28837138414382935
Final Model 
Model: "functional_711"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_842 (Conv2D)             (None, 224, 224, 32) 2432        input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_843 (Conv2D)             (None, 224, 224, 32) 1024        conv2d_842[120][0]               
__________________________________________________________________________________________________
conv2d_844 (Conv2D)             (None, 224, 224, 32) 96          input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_462 (BatchN (None, 224, 224, 32) 128         conv2d_843[120][0]               
__________________________________________________________________________________________________
batch_normalization_463 (BatchN (None, 224, 224, 32) 128         conv2d_844[120][0]               
__________________________________________________________________________________________________
add_231 (Add)                   (None, 224, 224, 32) 0           batch_normalization_462[120][0]  
                                                                 batch_normalization_463[120][0]  
__________________________________________________________________________________________________
conv2d_845 (Conv2D)             (None, 224, 224, 32) 25632       add_231[120][0]                  
__________________________________________________________________________________________________
max_pooling2d_183 (MaxPooling2D (None, 112, 112, 32) 0           conv2d_845[120][0]               
__________________________________________________________________________________________________
conv2d_1011 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_183[120][0]        
__________________________________________________________________________________________________
max_pooling2d_220 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_1011[61][0]               
__________________________________________________________________________________________________
conv2d_1218 (Conv2D)            (None, 56, 56, 128)  73856       max_pooling2d_220[61][0]         
__________________________________________________________________________________________________
conv2d_1219 (Conv2D)            (None, 56, 56, 128)  73856       max_pooling2d_220[61][0]         
__________________________________________________________________________________________________
conv2d_1220 (Conv2D)            (None, 56, 56, 128)  16384       conv2d_1218[2][0]                
__________________________________________________________________________________________________
conv2d_1221 (Conv2D)            (None, 56, 56, 128)  16384       conv2d_1219[2][0]                
__________________________________________________________________________________________________
batch_normalization_666 (BatchN (None, 56, 56, 128)  512         conv2d_1220[2][0]                
__________________________________________________________________________________________________
batch_normalization_667 (BatchN (None, 56, 56, 128)  512         conv2d_1221[2][0]                
__________________________________________________________________________________________________
add_333 (Add)                   (None, 56, 56, 128)  0           batch_normalization_666[2][0]    
                                                                 batch_normalization_667[2][0]    
__________________________________________________________________________________________________
max_pooling2d_265 (MaxPooling2D (None, 28, 28, 128)  0           add_333[2][0]                    
__________________________________________________________________________________________________
flatten_355 (Flatten)           (None, 100352)       0           max_pooling2d_265[2][0]          
__________________________________________________________________________________________________
dropout_355 (Dropout)           (None, 100352)       0           flatten_355[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            100353      dropout_355[0][0]                
==================================================================================================
Total params: 329,793
Trainable params: 329,153
Non-trainable params: 640
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Id', 'Conv_3_1', 'None', 'Conv_3_1', 'No'] Val Loss: 2.2024571895599365
Block 1 ['None', 'Id', 'No', 'Add', 'Id', 'Conv_3_1'] Val Loss: 0.6492478251457214
Block 2 ['None', 'Id', 'No', 'Add', 'Conv_3_1', 'Conv_3_1'] Val Loss: 0.3852015435695648
Block 0 ['None', 'Id', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.2244783341884613
Block 1 ['None', 'Id', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.1577642858028412
Block 2 ['None', 'Id', 'No', 'Add', 'Conv_3_1', 'Id'] Val Loss: 0.2992323637008667
Block 0 ['None', 'Id', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.2613446116447449
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.28090664744377136
Block 2 ['None', 'Id', 'No', 'Add', 'Conv_3_1', 'Id'] Val Loss: 0.31882864236831665
Block 0 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.6123417615890503
Block 1 ['Add', 'Conv_3_1', 'Conv_3_1', 'Add', 'Conv_3_1', 'Conv_3_1'] Val Loss: 0.24084140360355377
Block 2 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.9459981918334961
Final Model 
Model: "functional_1417"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_2099 (Conv2D)            (None, 224, 224, 32) 896         input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_457 (MaxPooling2D (None, 112, 112, 32) 0           conv2d_2099[120][0]              
__________________________________________________________________________________________________
conv2d_2278 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_457[120][0]        
__________________________________________________________________________________________________
conv2d_2279 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_457[120][0]        
__________________________________________________________________________________________________
conv2d_2280 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_2278[61][0]               
__________________________________________________________________________________________________
conv2d_2281 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_2279[61][0]               
__________________________________________________________________________________________________
batch_normalization_1246 (Batch (None, 112, 112, 64) 256         conv2d_2280[61][0]               
__________________________________________________________________________________________________
batch_normalization_1247 (Batch (None, 112, 112, 64) 256         conv2d_2281[61][0]               
__________________________________________________________________________________________________
add_623 (Add)                   (None, 112, 112, 64) 0           batch_normalization_1246[61][0]  
                                                                 batch_normalization_1247[61][0]  
__________________________________________________________________________________________________
conv2d_2282 (Conv2D)            (None, 112, 112, 64) 36928       add_623[61][0]                   
__________________________________________________________________________________________________
conv2d_2283 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_457[120][0]        
__________________________________________________________________________________________________
conv2d_2284 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_2282[61][0]               
__________________________________________________________________________________________________
conv2d_2285 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_2283[61][0]               
__________________________________________________________________________________________________
batch_normalization_1248 (Batch (None, 112, 112, 64) 256         conv2d_2284[61][0]               
__________________________________________________________________________________________________
batch_normalization_1249 (Batch (None, 112, 112, 64) 256         conv2d_2285[61][0]               
__________________________________________________________________________________________________
add_624 (Add)                   (None, 112, 112, 64) 0           batch_normalization_1248[61][0]  
                                                                 batch_normalization_1249[61][0]  
__________________________________________________________________________________________________
max_pooling2d_495 (MaxPooling2D (None, 56, 56, 64)   0           add_624[61][0]                   
__________________________________________________________________________________________________
conv2d_2539 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_495[61][0]         
__________________________________________________________________________________________________
max_pooling2d_553 (MaxPooling2D (None, 28, 28, 64)   0           conv2d_2539[2][0]                
__________________________________________________________________________________________________
flatten_708 (Flatten)           (None, 50176)        0           max_pooling2d_553[2][0]          
__________________________________________________________________________________________________
dropout_708 (Dropout)           (None, 50176)        0           flatten_708[0][0]                
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            50177       dropout_708[0][0]                
==================================================================================================
Total params: 197,825
Trainable params: 197,313
Non-trainable params: 512
__________________________________________________________________________________________________
FPNAS Optimizing Architecture
Block 0 ['Add', 'Conv_3_1', 'Conv_3_1', 'None', 'Conv_3_1', 'No'] Val Loss: 1.443359136581421
Block 1 ['None', 'Conv_5_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.4556773602962494
Block 2 ['None', 'Id', 'No', 'None', 'Conv_3_1', 'No'] Val Loss: 0.5606778860092163
Block 0 ['None', 'Conv_5_1', 'No', 'Add', 'Id', 'Conv_5_1'] Val Loss: 0.2805005609989166
Block 1 ['Add', 'Conv_5_1', 'Id', 'None', 'Conv_5_1', 'No'] Val Loss: 0.21801328659057617
Block 2 ['None', 'Conv_3_1', 'No', 'Add', 'Conv_3_1', 'Conv_3_1'] Val Loss: 0.8745840787887573
Block 0 ['Add', 'Conv_3_1', 'Conv_3_1', 'None', 'Id', 'No'] Val Loss: 1.8606033325195312
Block 1 ['None', 'Conv_3_1', 'No', 'None', 'Id', 'No'] Val Loss: 0.21544131636619568
Block 2 ['None', 'Conv_5_1', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.26744621992111206
Block 0 ['None', 'Id', 'No', 'None', 'Conv_5_1', 'No'] Val Loss: 0.23180818557739258
Block 1 ['Add', 'Conv_3_1', 'Conv_3_1', 'Add', 'Conv_3_1', 'Conv_3_1'] Val Loss: 0.6716467142105103
Block 2 ['None', 'Conv_3_1', 'No', 'Add', 'Id', 'Conv_3_1'] Val Loss: 1.8934768438339233
Final Model 
Model: "functional_2835"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_4847 (Conv2D)            (None, 224, 224, 32) 2432        input_2[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1056 (MaxPooling2 (None, 112, 112, 32) 0           conv2d_4847[120][0]              
__________________________________________________________________________________________________
conv2d_4930 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_1056[120][0]       
__________________________________________________________________________________________________
conv2d_4931 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_1056[120][0]       
__________________________________________________________________________________________________
conv2d_4932 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_4930[61][0]               
__________________________________________________________________________________________________
conv2d_4933 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_4931[61][0]               
__________________________________________________________________________________________________
batch_normalization_2692 (Batch (None, 112, 112, 64) 256         conv2d_4932[61][0]               
__________________________________________________________________________________________________
batch_normalization_2693 (Batch (None, 112, 112, 64) 256         conv2d_4933[61][0]               
__________________________________________________________________________________________________
add_1346 (Add)                  (None, 112, 112, 64) 0           batch_normalization_2692[61][0]  
                                                                 batch_normalization_2693[61][0]  
__________________________________________________________________________________________________
conv2d_4934 (Conv2D)            (None, 112, 112, 64) 36928       add_1346[61][0]                  
__________________________________________________________________________________________________
conv2d_4935 (Conv2D)            (None, 112, 112, 64) 18496       max_pooling2d_1056[120][0]       
__________________________________________________________________________________________________
conv2d_4936 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_4934[61][0]               
__________________________________________________________________________________________________
conv2d_4937 (Conv2D)            (None, 112, 112, 64) 4096        conv2d_4935[61][0]               
__________________________________________________________________________________________________
batch_normalization_2694 (Batch (None, 112, 112, 64) 256         conv2d_4936[61][0]               
__________________________________________________________________________________________________
batch_normalization_2695 (Batch (None, 112, 112, 64) 256         conv2d_4937[61][0]               
__________________________________________________________________________________________________
add_1347 (Add)                  (None, 112, 112, 64) 0           batch_normalization_2694[61][0]  
                                                                 batch_normalization_2695[61][0]  
__________________________________________________________________________________________________
max_pooling2d_1074 (MaxPooling2 (None, 56, 56, 64)   0           add_1347[61][0]                  
__________________________________________________________________________________________________
conv2d_5178 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_1074[61][0]        
__________________________________________________________________________________________________
conv2d_5179 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_1074[61][0]        
__________________________________________________________________________________________________
conv2d_5180 (Conv2D)            (None, 56, 56, 64)   4096        conv2d_5178[2][0]                
__________________________________________________________________________________________________
conv2d_5181 (Conv2D)            (None, 56, 56, 64)   4096        conv2d_5179[2][0]                
__________________________________________________________________________________________________
batch_normalization_2826 (Batch (None, 56, 56, 64)   256         conv2d_5180[2][0]                
__________________________________________________________________________________________________
batch_normalization_2827 (Batch (None, 56, 56, 64)   256         conv2d_5181[2][0]                
__________________________________________________________________________________________________
add_1413 (Add)                  (None, 56, 56, 64)   0           batch_normalization_2826[2][0]   
                                                                 batch_normalization_2827[2][0]   
__________________________________________________________________________________________________
max_pooling2d_1129 (MaxPooling2 (None, 28, 28, 64)   0           add_1413[2][0]                   
__________________________________________________________________________________________________
flatten_1417 (Flatten)          (None, 50176)        0           max_pooling2d_1129[2][0]         
__________________________________________________________________________________________________
dropout_1417 (Dropout)          (None, 50176)        0           flatten_1417[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            50177       dropout_1417[0][0]               
==================================================================================================
Total params: 244,993
Trainable params: 244,225
Non-trainable params: 768
__________________________________________________________________________________________________
